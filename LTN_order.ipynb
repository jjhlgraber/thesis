{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import ltn\n",
    "import itertools\n",
    "from order_utils import BaselineRelationalModel, BaselineRelationalModelConcat, AbstractorOrderModel, BaselineRelationalIndependentModel, plot_mp\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "import networkx as nx\n",
    "import random\n",
    "import os\n",
    "\n",
    "from custom_fuzzy_ops import ImpliesReichenbachSigmoidal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacency_anti_transitive(n):\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(range(n))\n",
    "\n",
    "    while True:\n",
    "        added_edge = False\n",
    "        adjacency = nx.adjacency_matrix(G).toarray()\n",
    "        sorted_non_edges = sorted(nx.non_edges(G), key=lambda k: random.random())\n",
    "        for u, v in sorted_non_edges:\n",
    "            if G.has_edge(v, u):\n",
    "                continue\n",
    "            if not np.logical_and(adjacency[u], adjacency[:,v]).any() and \\\n",
    "                not np.logical_and(adjacency[u], adjacency[v]).any() and \\\n",
    "                not np.logical_and(adjacency[:,u], adjacency[:,v]).any():\n",
    "                G.add_edge(u, v)\n",
    "                added_edge = True\n",
    "                break\n",
    "        if not added_edge:\n",
    "            break\n",
    "\n",
    "    adjacency = nx.adjacency_matrix(G).toarray()\n",
    "    adjacency = torch.tensor(adjacency)\n",
    "    return adjacency\n",
    "\n",
    "def adjacency_triangular_lattice(n, periodic=True):\n",
    "    lattice = nx.triangular_lattice_graph(n//2, n//2, periodic=periodic)\n",
    "    adjacency = nx.adjacency_matrix(lattice).toarray()[np.arange(n),:][:,np.arange(n)]\n",
    "    adjacency += np.eye(adjacency.shape[0]).astype(int)\n",
    "\n",
    "    adjacency = torch.tensor(adjacency)\n",
    "    return adjacency\n",
    "\n",
    "def adjacency_lattice(n, dim, periodic=True, distance=2):\n",
    "    div = int(n**(1./dim))\n",
    "    # rest = n % dim\n",
    "    grid_dims = dim * [div]\n",
    "    # grid_dims[0] += rest\n",
    "    grid_dims\n",
    "\n",
    "    lattice = nx.grid_graph(grid_dims, periodic=periodic)\n",
    "    for u, v in lattice.edges():\n",
    "        for i in range(1, distance + 1):\n",
    "            if i != 1:  # Avoid duplicate edges\n",
    "                neighbors = [(u[0] + i, u[1]), (u[0] - i, u[1]),\n",
    "                             (u[0], u[1] + i), (u[0], u[1] - i)]\n",
    "                for neighbor in neighbors:\n",
    "                    if neighbor in lattice.nodes:\n",
    "                        lattice.add_edge(u, neighbor)\n",
    "\n",
    "    adjacency = nx.adjacency_matrix(lattice).toarray()\n",
    "    adjacency += np.eye(adjacency.shape[0]).astype(int)\n",
    "\n",
    "    adjacency = torch.tensor(adjacency)\n",
    "    return adjacency\n",
    "\n",
    "def adjacency_total_order(n):\n",
    "\n",
    "    adjacency = torch.triu(torch.ones(n,n))\n",
    "\n",
    "    return adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacency_from_string(N=1000, string='O'):\n",
    "    # Make a plot with \"HELLO\" text; save as PNG\n",
    "    fig, ax = plt.subplots(figsize=(4, 1))\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, 0.5, string, va='center', ha='center', size=85)\n",
    "    fig.savefig('hello.png')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Open this PNG and draw random points from it\n",
    "    from matplotlib.image import imread\n",
    "    data = imread('hello.png')[::-1, :, 0].T\n",
    "    mask = (data < 1)\n",
    "    indices = np.random.choice(mask.sum(), N,replace=False)\n",
    "    X = np.argwhere(mask)[indices].astype(float)\n",
    "\n",
    "    X[:, 0] /= data.shape[0]\n",
    "    X[:, 1] /= data.shape[0]\n",
    "    X = X[np.argsort(X[:, 0])]\n",
    "    X = X[np.argsort(X[:, 1])]\n",
    "\n",
    "    pos = {node: (i, j) for node, (i, j) in enumerate(X)}\n",
    "    G = nx.random_geometric_graph(X.shape[0], 0.1, pos=pos)\n",
    "    adjacency = nx.adjacency_matrix(G).toarray()\n",
    "    adjacency += np.eye(adjacency.shape[0]).astype(int)\n",
    "    adjacency = torch.tensor(adjacency)\n",
    "    return adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs_adjacency(adjacency):\n",
    "    pos_pairs = torch.argwhere(adjacency==1)\n",
    "    neg_pairs = torch.argwhere(adjacency==0)\n",
    "    return pos_pairs, neg_pairs\n",
    "\n",
    "\n",
    "def get_samples_adjacency(pos_pairs, neg_pairs, train_split_pos, train_split_neg):\n",
    "    pos_n_train_points = int(pos_pairs.size(0) * train_split_pos)\n",
    "    neg_n_train_points = int(neg_pairs.size(0) * train_split_neg)\n",
    "\n",
    "    pos_sample_indices = np.random.choice(len(pos_pairs), pos_n_train_points, replace=False)\n",
    "    neg_sample_indices = np.random.choice(len(neg_pairs), neg_n_train_points, replace=False)\n",
    "\n",
    "    pos_sample = pos_pairs[pos_sample_indices]\n",
    "    neg_sample = neg_pairs[neg_sample_indices]\n",
    "\n",
    "    return pos_sample, neg_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_constants(num_objects, object_dim, feature_type=\"onehot\"):\n",
    "    if feature_type == \"gaussian\":\n",
    "        learn_embed = False\n",
    "        embed = torch.nn.Embedding(\n",
    "        num_embeddings=num_objects, embedding_dim=object_dim\n",
    "        )\n",
    "        torch.nn.init.normal_(embed.weight, mean=0.0, std=1.0)\n",
    "        embed.weight.requires_grad = learn_embed\n",
    "        constants_tensor = embed.weight\n",
    "    elif feature_type == \"index\":\n",
    "        constants_tensor = torch.arange(num_objects).unsqueeze(-1)\n",
    "    else:\n",
    "        assert num_objects == object_dim\n",
    "        constants_tensor = torch.eye(num_objects)\n",
    "\n",
    "    constants = [ltn.Constant(features, trainable=False) for features in constants_tensor]\n",
    "\n",
    "    return constants, constants_tensor\n",
    "\n",
    "def get_pairs_total_order(num_objects):\n",
    "    object_pairs = torch.Tensor(list(itertools.permutations(range(num_objects), r=2))).int()\n",
    "    object_order_relations = (object_pairs[:,0] < object_pairs[:, 1])\n",
    "\n",
    "    pos_pairs = object_pairs[object_order_relations]\n",
    "    neg_pairs = object_pairs[object_order_relations == False]\n",
    "\n",
    "    return pos_pairs, neg_pairs\n",
    "\n",
    "def get_samples_total_order(num_objects, pos_pairs, neg_pairs, pos_chain_depth, train_split_pos, train_split_neg):\n",
    "\n",
    "    if pos_chain_depth:\n",
    "        pos_sample = []\n",
    "        for j in range(pos_chain_depth):\n",
    "            pos_sample += [[i, i+j+1] for i in range(num_objects-(j+1))]\n",
    "\n",
    "        pos_sample = torch.tensor(pos_sample)\n",
    "\n",
    "        indices_pos_chain = torch.zeros(len(pos_pairs))\n",
    "\n",
    "        for pair in pos_sample:\n",
    "           indices_pos_chain += (pos_pairs == pair).all(-1).int()\n",
    "\n",
    "        indices_pos_chain = ~ indices_pos_chain.bool()\n",
    "\n",
    "        pos_pairs_to_sample_from = pos_pairs[indices_pos_chain]\n",
    "    else:\n",
    "        pos_sample = torch.tensor([]).int()\n",
    "        pos_pairs_to_sample_from = pos_pairs\n",
    "\n",
    "    neg_n_train_points = int(neg_pairs.size(0) * train_split_neg)\n",
    "    pos_n_train_points = int(neg_pairs.size(0) * train_split_pos) - len(pos_sample)\n",
    "    if pos_n_train_points < 0:\n",
    "        pos_n_train_points = 0\n",
    "\n",
    "    pos_sample_indices = np.random.choice(len(pos_pairs_to_sample_from), pos_n_train_points, replace=False)\n",
    "    neg_sample_indices = np.random.choice(len(neg_pairs), neg_n_train_points, replace=False)\n",
    "\n",
    "    pos_sample = torch.cat((pos_sample, pos_pairs_to_sample_from[pos_sample_indices]))\n",
    "    neg_sample = neg_pairs[neg_sample_indices]\n",
    "    if pos_sample.shape[0] == 0:\n",
    "        pos_sample = None\n",
    "    if neg_sample.shape[0] == 0:\n",
    "        neg_sample = None\n",
    "\n",
    "    return pos_sample, neg_sample\n",
    " \n",
    "def get_eye_3D(num_objects):\n",
    "    triples = product(range(num_objects), repeat=3)\n",
    "    triples_with_id = [triple for triple in triples if len(set(triple)) < 3]\n",
    "\n",
    "    eye_3D = torch.ones(num_objects, num_objects, num_objects)\n",
    "    for i, j, k in triples_with_id:\n",
    "        eye_3D[i, j, k] = 0\n",
    "    eye_3D = eye_3D.bool()\n",
    "    return eye_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Not = ltn.Connective(ltn.fuzzy_ops.NotStandard())\n",
    "And = ltn.Connective(ltn.fuzzy_ops.AndProd())\n",
    "Or = ltn.Connective(ltn.fuzzy_ops.OrProbSum())\n",
    "Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "Equiv = ltn.Connective(ltn.fuzzy_ops.Equiv(ltn.fuzzy_ops.AndProd(), ltn.fuzzy_ops.ImpliesReichenbach()))\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "Exists = ltn.Quantifier(ltn.fuzzy_ops.AggregPMean(p=6), quantifier=\"e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderabstractor_kwargs = {\n",
    "    \"num_layers\": 1,\n",
    "    \"norm\": None,  # Example normalization layer\n",
    "    \"use_pos_embedding\": True,\n",
    "    \"use_learned_symbols\": False,\n",
    "    \"learn_symbol_per_position\": False,\n",
    "    \"use_symbolic_attention\": False,\n",
    "    \"object_dim\": 32,\n",
    "    \"symbol_dim\": 32,  # Using a different symbol dimension\n",
    "    \"num_heads\": 1,\n",
    "    \"ff_dim\": 64,\n",
    "    \"dropout\": 0.1,\n",
    "    \"MHA_kwargs\": {\n",
    "        \"use_bias\": False,\n",
    "        \"activation\": torch.nn.Identity(),  # Different activation function\n",
    "        # \"activation\": nn.Softmax(-1),\n",
    "        # \"activation\": nn.Sigmoid(),\n",
    "        # \"activation\": sparsemax,\n",
    "        \"use_scaling\": True,\n",
    "        \"shared_kv_proj\": False,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sat(heatmap, ground_truth, mask=None, p=1):\n",
    "    if mask is None:\n",
    "        mask = torch.ones_like(ground_truth).bool()\n",
    "    xs = 1 - torch.abs(ground_truth - heatmap)\n",
    "    xs = torch.pow(1. - xs, p)\n",
    "    numerator = torch.sum(torch.where(~mask, torch.zeros_like(xs), xs))\n",
    "    denominator = torch.sum(mask)\n",
    "    sat = (1. - torch.pow(torch.div(numerator, denominator), 1 / p)).item()\n",
    "    return sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, constants_tensor, epoch_steps=50, epochs=1000, reflective=True, transitive=True, anti_transitive=False,\n",
    "          symmetric=False,\n",
    "          anti_symmetric=True, \n",
    "          connected=True,\n",
    "          LEM=True,\n",
    "          neg_examples=None, pos_examples=None, lr=0.001,\n",
    "          switch=False,\n",
    "          Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach()),\n",
    "          Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\"),\n",
    "          Forall_custom=ltn.Quantifier(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=10, stable=True), quantifier='f'),\n",
    "          first_run=True,\n",
    "          sat_agg=ltn.fuzzy_ops.SatAgg(),\n",
    "          ground_truth=None,):\n",
    "    \n",
    "    \n",
    "    heatmap_data = []\n",
    "    train_loss = []\n",
    "\n",
    "    if first_run:\n",
    "        x1 = ltn.Variable(\"x1\", constants_tensor)\n",
    "        x2 = ltn.Variable(\"x2\", constants_tensor)\n",
    "        query = model(x1,x2).value.detach().numpy()\n",
    "        heatmap_data.append(query)\n",
    "\n",
    "\n",
    "    # we need to learn the parameters of the predicate C\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    last_loss = np.inf\n",
    "    \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x1 = ltn.Variable(\"x1\", constants_tensor)\n",
    "        x2 = ltn.Variable(\"x2\", constants_tensor)\n",
    "        x3 = ltn.Variable(\"x3\", constants_tensor)\n",
    "\n",
    "        fuzzy_theory = []\n",
    "        fuzzy_weighted = []\n",
    "        if pos_examples is not None:\n",
    "            pos_x = ltn.Variable(\"pos_x\", constants_tensor[pos_examples[:,0]])\n",
    "            pos_y = ltn.Variable(\"pos_y\", constants_tensor[pos_examples[:,1]])\n",
    "            pos_x, pos_y = ltn.diag(pos_x, pos_y)\n",
    "            axiom_pos = Forall([pos_x, pos_y], model(pos_x, pos_y))\n",
    "            fuzzy_theory.append(axiom_pos)\n",
    "        if neg_examples is not None:\n",
    "            neg_x = ltn.Variable(\"neg_x\", constants_tensor[neg_examples[:,0]])\n",
    "            neg_y = ltn.Variable(\"neg_y\", constants_tensor[neg_examples[:,1]])\n",
    "            neg_x, neg_y = ltn.diag(neg_x, neg_y)\n",
    "            axiom_neg = Forall([neg_x, neg_y], Not(model(neg_x, neg_y)))\n",
    "            fuzzy_theory.append(axiom_neg)\n",
    "\n",
    "        if reflective:\n",
    "            fuzzy_theory.append(Forall(x1, model(x1, x1)))\n",
    "        if transitive:\n",
    "            fuzzy_weighted.append(\n",
    "                Forall_custom([x1, x2, x3], Implies(And(model(x1, x2), model(x2, x3)), model(x1, x3)),\n",
    "                                              cond_vars=[x1, x2, x3],\n",
    "                                              cond_fn=lambda x, y, z: eye_3D))\n",
    "                                            \n",
    "\n",
    "\n",
    "        if anti_transitive:\n",
    "            fuzzy_weighted.append(Forall_custom([x1, x2, x3], Implies(And(model(x1, x2), model(x2, x3)), Not(model(x1, x3))),) )\n",
    "\n",
    "        if symmetric:\n",
    "            fuzzy_theory.append(Forall_custom([x1, x2],\n",
    "                Implies(model(x1, x2), model(x2, x1)),\n",
    "                cond_vars=[x1, x2],\n",
    "                cond_fn=lambda x, y: ~torch.eye(num_objects, dtype=bool),\n",
    "                ))\n",
    "\n",
    "        if anti_symmetric:\n",
    "            fuzzy_theory.append(Forall([x1, x2],\n",
    "                Implies(model(x1, x2), Not(model(x2, x1))),\n",
    "                cond_vars=[x1, x2],\n",
    "                cond_fn=lambda x, y: ~torch.eye(num_objects, dtype=bool),\n",
    "                ))\n",
    "            \n",
    "        if connected:\n",
    "            axiom_connected = Forall_custom([x1, x2],\n",
    "                Or(model(x1, x2), model(x2, x1)),\n",
    "                )\n",
    "\n",
    "            fuzzy_theory.append(axiom_connected)\n",
    "        \n",
    "        if LEM:\n",
    "            axiom_lem = Forall_custom([x1, x2],\n",
    "                Or(model(x1, x2), Not(model(x1, x2))),\n",
    "                )\n",
    "            # axiom_lem = Forall_custom([x1, x2],\n",
    "            #     Implies(Not(model(x1, x2)), model(x1, x2)),\n",
    "            #     )\n",
    "\n",
    "            fuzzy_theory.append(axiom_lem)\n",
    "\n",
    "        weighted = False\n",
    "        if weighted:\n",
    "            sat_weight = 0.9\n",
    "            satisfiablity = sat_weight * sat_agg(*fuzzy_theory) + (1 - sat_weight) * sat_agg(*fuzzy_weighted)\n",
    "        else:\n",
    "            fuzzy_theory += fuzzy_weighted\n",
    "            satisfiablity = sat_agg(*fuzzy_theory)\n",
    "\n",
    "\n",
    "        loss = 1. - satisfiablity\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch%epoch_steps == 0:\n",
    "            with torch.no_grad():\n",
    "                train_loss.append(loss.item())\n",
    "\n",
    "                print(\"Epoch %d: Train Sat Level %.3f \"%(epoch, satisfiablity))\n",
    "                query = model(x1,x2).value.detach().numpy()\n",
    "                heatmap_data.append(query)\n",
    "                if ground_truth is not None:\n",
    "                    pred = torch.tensor(query > 0.5)\n",
    "                    val_acc = (pred == ground_truth).sum() / (ground_truth.shape[0]**2)\n",
    "                    print(\"Overall acc %.3f \"%(val_acc))\n",
    "\n",
    "                    mask = ~torch.eye(object_dim).bool()\n",
    "                    print(\"Overall sat %.3f\"%(get_sat(query, ground_truth, mask=mask, p=1)))\n",
    "\n",
    "                # if np.allclose(loss.item(), last_loss, atol=1e-04, equal_nan=False) and epoch>25:\n",
    "                # # 1 - loss > 0.995 or \n",
    "                \n",
    "                #     if switch:\n",
    "                #         print()\n",
    "                #         print(epoch/epoch_steps)\n",
    "                #         torch.save(model, f\"checkpoints/chain_{object_dim}.PT\")\n",
    "                #         # break\n",
    "                    \n",
    "                #         switch = False\n",
    "                #         transitive = True\n",
    "                #         # Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=6), quantifier=\"f\")\n",
    "                #     else:\n",
    "                #         break\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            # last_loss = loss\n",
    "            \n",
    "    print(\"Training finished at Epoch %d with Sat Level %.3f\" %(epoch, 1 - loss))\n",
    "    \n",
    "    return heatmap_data, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_training(num_objects = 32, object_dim = None, feature_type = \"onehot\" ,pos_chain_depth = 1,\n",
    "    train_split_pos = 0.,\n",
    "    train_split_neg = 0.,):\n",
    "    if object_dim is None:\n",
    "        object_dim = num_objects\n",
    "\n",
    "    # adjacency = adjacency_anti_transitive(num_objects)\n",
    "    # adjacency = adjacency_triangular_lattice(num_objects)\n",
    "    # adjacency = adjacency_lattice(num_objects, \n",
    "    #                               dim=2,\n",
    "    #                             #   dim=int(np.log2(num_objects))\n",
    "    #                             distance=3,\n",
    "    #                             periodic=False\n",
    "    #                               )\n",
    "    # adjacency = adjacency_from_string(num_objects, \"O\")\n",
    "    adjacency = adjacency_total_order(num_objects)\n",
    "\n",
    "\n",
    "    # plt.imshow(adjacency, cmap='hot')\n",
    "    # plt.show()\n",
    "    # nx.draw(G, with_labels=True, arrows=True, pos=pos)\n",
    "\n",
    "\n",
    "    constants, constants_tensor = get_constants(num_objects, object_dim, feature_type)\n",
    "    # pos_pairs, neg_pairs = get_pairs_adjacency(adjacency=adjacency)\n",
    "    # pos_sample, neg_sample = get_samples_adjacency(pos_pairs, neg_pairs, train_split_pos, train_split_neg)\n",
    "\n",
    "    pos_pairs, neg_pairs = get_pairs_total_order(num_objects)\n",
    "    pos_sample, neg_sample = get_samples_total_order(num_objects, pos_pairs, neg_pairs, pos_chain_depth, train_split_pos, train_split_neg)\n",
    "    eye_3D = get_eye_3D(num_objects)\n",
    "    return num_objects, object_dim, adjacency, constants, constants_tensor, pos_pairs, neg_pairs, pos_sample, neg_sample, eye_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "(num_objects, object_dim, adjacency, \n",
    " constants, constants_tensor, pos_pairs, \n",
    " neg_pairs, pos_sample, neg_sample, \n",
    " eye_3D) = set_training(num_objects = 32, object_dim = None, \n",
    "                        feature_type = \"index\" ,\n",
    "                        # feature_type = \"onehot\" ,\n",
    "                        pos_chain_depth = 1,\n",
    "                        train_split_pos = 0,\n",
    "                        train_split_neg = 0)\n",
    "\n",
    "pos_examples = pos_sample \n",
    "neg_examples = neg_sample\n",
    "\n",
    "# pos_examples = torch.Tensor([[i, i+1] for i in range(8-1)]).int()[[0,2,4,5,6]]\n",
    "# neg_examples = torch.Tensor([[i+2, i] for i in range(8-2)]).int()\n",
    "\n",
    "train_kwargs = dict(\n",
    "    epochs=300, epoch_steps=5,\n",
    "    reflective=True,\n",
    "    transitive=True,\n",
    "    anti_transitive=False,\n",
    "    symmetric=False,\n",
    "    anti_symmetric=True,\n",
    "    connected=True,\n",
    "    LEM=False,\n",
    "    pos_examples=pos_examples,\n",
    "    neg_examples=neg_examples,\n",
    "    # lr=0.01,\n",
    "    lr=0.01,\n",
    "    constants_tensor=constants_tensor,\n",
    "    switch=False,\n",
    "    ground_truth=adjacency\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connective(connective_op=ImpliesReichenbach(stable=True))\n",
      "Epoch 0: Train Sat Level 0.642 \n",
      "Overall acc 0.533 \n",
      "Overall sat 0.500\n",
      "Epoch 5: Train Sat Level 0.649 \n",
      "Overall acc 0.546 \n",
      "Overall sat 0.501\n",
      "Epoch 10: Train Sat Level 0.656 \n",
      "Overall acc 0.546 \n",
      "Overall sat 0.502\n",
      "Epoch 15: Train Sat Level 0.663 \n",
      "Overall acc 0.546 \n",
      "Overall sat 0.503\n",
      "Epoch 20: Train Sat Level 0.669 \n",
      "Overall acc 0.556 \n",
      "Overall sat 0.504\n",
      "Epoch 25: Train Sat Level 0.676 \n",
      "Overall acc 0.608 \n",
      "Overall sat 0.506\n",
      "Epoch 30: Train Sat Level 0.683 \n",
      "Overall acc 0.650 \n",
      "Overall sat 0.508\n",
      "Epoch 35: Train Sat Level 0.689 \n",
      "Overall acc 0.661 \n",
      "Overall sat 0.511\n",
      "Epoch 40: Train Sat Level 0.695 \n",
      "Overall acc 0.697 \n",
      "Overall sat 0.514\n",
      "Epoch 45: Train Sat Level 0.701 \n",
      "Overall acc 0.696 \n",
      "Overall sat 0.519\n",
      "Epoch 50: Train Sat Level 0.707 \n",
      "Overall acc 0.706 \n",
      "Overall sat 0.525\n",
      "Epoch 55: Train Sat Level 0.713 \n",
      "Overall acc 0.719 \n",
      "Overall sat 0.531\n",
      "Epoch 60: Train Sat Level 0.719 \n",
      "Overall acc 0.727 \n",
      "Overall sat 0.539\n",
      "Epoch 65: Train Sat Level 0.725 \n",
      "Overall acc 0.732 \n",
      "Overall sat 0.547\n",
      "Epoch 70: Train Sat Level 0.731 \n",
      "Overall acc 0.742 \n",
      "Overall sat 0.556\n",
      "Epoch 75: Train Sat Level 0.736 \n",
      "Overall acc 0.747 \n",
      "Overall sat 0.564\n",
      "Epoch 80: Train Sat Level 0.742 \n",
      "Overall acc 0.753 \n",
      "Overall sat 0.573\n",
      "Epoch 85: Train Sat Level 0.748 \n",
      "Overall acc 0.759 \n",
      "Overall sat 0.582\n",
      "Epoch 90: Train Sat Level 0.754 \n",
      "Overall acc 0.761 \n",
      "Overall sat 0.591\n",
      "Epoch 95: Train Sat Level 0.759 \n",
      "Overall acc 0.758 \n",
      "Overall sat 0.599\n",
      "Epoch 100: Train Sat Level 0.765 \n",
      "Overall acc 0.755 \n",
      "Overall sat 0.607\n",
      "Epoch 105: Train Sat Level 0.770 \n",
      "Overall acc 0.755 \n",
      "Overall sat 0.615\n",
      "Epoch 110: Train Sat Level 0.775 \n",
      "Overall acc 0.754 \n",
      "Overall sat 0.622\n",
      "Epoch 115: Train Sat Level 0.779 \n",
      "Overall acc 0.755 \n",
      "Overall sat 0.628\n",
      "Epoch 120: Train Sat Level 0.783 \n",
      "Overall acc 0.757 \n",
      "Overall sat 0.633\n",
      "Epoch 125: Train Sat Level 0.787 \n",
      "Overall acc 0.757 \n",
      "Overall sat 0.638\n",
      "Epoch 130: Train Sat Level 0.791 \n",
      "Overall acc 0.757 \n",
      "Overall sat 0.643\n",
      "Epoch 135: Train Sat Level 0.794 \n",
      "Overall acc 0.758 \n",
      "Overall sat 0.646\n",
      "Epoch 140: Train Sat Level 0.797 \n",
      "Overall acc 0.758 \n",
      "Overall sat 0.650\n",
      "Epoch 145: Train Sat Level 0.799 \n",
      "Overall acc 0.758 \n",
      "Overall sat 0.653\n",
      "Epoch 150: Train Sat Level 0.802 \n",
      "Overall acc 0.758 \n",
      "Overall sat 0.655\n",
      "Epoch 155: Train Sat Level 0.804 \n",
      "Overall acc 0.759 \n",
      "Overall sat 0.658\n",
      "Epoch 160: Train Sat Level 0.806 \n",
      "Overall acc 0.759 \n",
      "Overall sat 0.660\n",
      "Epoch 165: Train Sat Level 0.808 \n",
      "Overall acc 0.759 \n",
      "Overall sat 0.662\n",
      "Epoch 170: Train Sat Level 0.810 \n",
      "Overall acc 0.760 \n",
      "Overall sat 0.663\n",
      "Epoch 175: Train Sat Level 0.811 \n",
      "Overall acc 0.760 \n",
      "Overall sat 0.665\n",
      "Epoch 180: Train Sat Level 0.813 \n",
      "Overall acc 0.760 \n",
      "Overall sat 0.666\n",
      "Epoch 185: Train Sat Level 0.814 \n",
      "Overall acc 0.760 \n",
      "Overall sat 0.668\n",
      "Epoch 190: Train Sat Level 0.816 \n",
      "Overall acc 0.761 \n",
      "Overall sat 0.669\n",
      "Epoch 195: Train Sat Level 0.817 \n",
      "Overall acc 0.765 \n",
      "Overall sat 0.671\n",
      "Epoch 200: Train Sat Level 0.818 \n",
      "Overall acc 0.766 \n",
      "Overall sat 0.672\n",
      "Epoch 205: Train Sat Level 0.820 \n",
      "Overall acc 0.767 \n",
      "Overall sat 0.673\n",
      "Epoch 210: Train Sat Level 0.821 \n",
      "Overall acc 0.767 \n",
      "Overall sat 0.675\n",
      "Epoch 215: Train Sat Level 0.822 \n",
      "Overall acc 0.768 \n",
      "Overall sat 0.676\n",
      "Epoch 220: Train Sat Level 0.823 \n",
      "Overall acc 0.770 \n",
      "Overall sat 0.677\n",
      "Epoch 225: Train Sat Level 0.824 \n",
      "Overall acc 0.771 \n",
      "Overall sat 0.678\n",
      "Epoch 230: Train Sat Level 0.824 \n",
      "Overall acc 0.772 \n",
      "Overall sat 0.679\n",
      "Epoch 235: Train Sat Level 0.825 \n",
      "Overall acc 0.772 \n",
      "Overall sat 0.680\n",
      "Epoch 240: Train Sat Level 0.826 \n",
      "Overall acc 0.773 \n",
      "Overall sat 0.681\n",
      "Epoch 245: Train Sat Level 0.827 \n",
      "Overall acc 0.773 \n",
      "Overall sat 0.682\n",
      "Epoch 250: Train Sat Level 0.828 \n",
      "Overall acc 0.773 \n",
      "Overall sat 0.683\n",
      "Epoch 255: Train Sat Level 0.828 \n",
      "Overall acc 0.773 \n",
      "Overall sat 0.684\n",
      "Epoch 260: Train Sat Level 0.829 \n",
      "Overall acc 0.773 \n",
      "Overall sat 0.684\n",
      "Epoch 265: Train Sat Level 0.829 \n",
      "Overall acc 0.773 \n",
      "Overall sat 0.685\n",
      "Epoch 270: Train Sat Level 0.830 \n",
      "Overall acc 0.773 \n",
      "Overall sat 0.686\n",
      "Epoch 275: Train Sat Level 0.831 \n",
      "Overall acc 0.774 \n",
      "Overall sat 0.686\n",
      "Epoch 280: Train Sat Level 0.831 \n",
      "Overall acc 0.774 \n",
      "Overall sat 0.687\n",
      "Epoch 285: Train Sat Level 0.832 \n",
      "Overall acc 0.775 \n",
      "Overall sat 0.687\n",
      "Epoch 290: Train Sat Level 0.832 \n",
      "Overall acc 0.775 \n",
      "Overall sat 0.688\n",
      "Epoch 295: Train Sat Level 0.832 \n",
      "Overall acc 0.776 \n",
      "Overall sat 0.688\n",
      "Training finished at Epoch 299 with Sat Level 0.833\n"
     ]
    }
   ],
   "source": [
    "train_kwargs[\"Forall\"] = ltn.Quantifier(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=10, stable=True), quantifier='f')\n",
    "train_kwargs[\"Forall_custom\"]= ltn.Quantifier(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=10, stable=True), quantifier='f')\n",
    "train_kwargs[\"sat_agg\"] = ltn.fuzzy_ops.SatAgg(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=2, stable=True))\n",
    "train_kwargs[\"Implies\"] = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "# train_kwargs[\"Implies\"] = ltn.Connective(ltn.fuzzy_ops.ImpliesGodel())\n",
    "\n",
    "# train_kwargs[\"Implies\"] = list(Implies_dict.values())[1]\n",
    "print(train_kwargs[\"Implies\"])\n",
    "\n",
    "\n",
    "first_run = True\n",
    "if first_run:\n",
    "    heatmap_data_ind = []\n",
    "    train_loss=[]\n",
    "    model = BaselineRelationalIndependentModel(object_dim)\n",
    "    # shape = model.lin.weight.shape\n",
    "    # model.lin.weight = torch.nn.Parameter(torch.zeros(shape), requires_grad=True)\n",
    "    AOM = ltn.Predicate(model)\n",
    "heatmap_data_ind_last, train_loss_last = train(AOM, **train_kwargs, first_run=first_run)\n",
    "heatmap_data_ind += heatmap_data_ind_last\n",
    "train_loss += train_loss_last\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae284161b27d43419033c89a50c26db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Frame', max=60), Output()), _dom_classes=('widget-interaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe4e23f0250>]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_mp(heatmap_data_ind, pos_examples=pos_examples, neg_examples=neg_examples)\n",
    "plt.plot(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[176], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(num_objects, object_dim, adjacency, \n",
    " constants, constants_tensor, pos_pairs, \n",
    " neg_pairs, pos_sample, neg_sample, \n",
    " eye_3D) = set_training(num_objects = 32, object_dim = None, \n",
    "                        # feature_type = \"index\" ,\n",
    "                        feature_type = \"onehot\" ,\n",
    "                        pos_chain_depth = 1,\n",
    "                        train_split_pos = 0,\n",
    "                        train_split_neg = 0.1)\n",
    "\n",
    "pos_examples = pos_sample \n",
    "neg_examples = neg_sample\n",
    "\n",
    "# pos_examples = torch.Tensor([[i, i+1] for i in range(8-1)]).int()[[0,2,4,5,6]]\n",
    "# neg_examples = torch.Tensor([[i+2, i] for i in range(8-2)]).int()\n",
    "\n",
    "train_kwargs = dict(\n",
    "    epochs=100, epoch_steps=5,\n",
    "    reflective=False,\n",
    "    transitive=True,\n",
    "    anti_transitive=False,\n",
    "    symmetric=False,\n",
    "    anti_symmetric=True,\n",
    "    connected=True,\n",
    "    LEM=False,\n",
    "    pos_examples=pos_examples,\n",
    "    neg_examples=neg_examples,\n",
    "    # lr=0.01,\n",
    "    lr=0.01,\n",
    "    constants_tensor=constants_tensor,\n",
    "    switch=False,\n",
    "    ground_truth=adjacency\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Sat Level 0.642 \n",
      "Overall acc 0.484 \n",
      "Overall sat 0.500\n",
      "Epoch 5: Train Sat Level 0.642 \n",
      "Overall acc 0.486 \n",
      "Overall sat 0.500\n",
      "Epoch 10: Train Sat Level 0.647 \n",
      "Overall acc 0.576 \n",
      "Overall sat 0.508\n",
      "Epoch 15: Train Sat Level 0.669 \n",
      "Overall acc 0.699 \n",
      "Overall sat 0.635\n",
      "Epoch 20: Train Sat Level 0.717 \n",
      "Overall acc 0.839 \n",
      "Overall sat 0.776\n",
      "Epoch 25: Train Sat Level 0.738 \n",
      "Overall acc 0.841 \n",
      "Overall sat 0.780\n",
      "Epoch 30: Train Sat Level 0.775 \n",
      "Overall acc 0.908 \n",
      "Overall sat 0.868\n",
      "Epoch 35: Train Sat Level 0.781 \n",
      "Overall acc 0.905 \n",
      "Overall sat 0.868\n",
      "Epoch 40: Train Sat Level 0.790 \n",
      "Overall acc 0.933 \n",
      "Overall sat 0.892\n",
      "Epoch 45: Train Sat Level 0.813 \n",
      "Overall acc 0.927 \n",
      "Overall sat 0.896\n",
      "Epoch 50: Train Sat Level 0.863 \n",
      "Overall acc 0.963 \n",
      "Overall sat 0.946\n",
      "Epoch 55: Train Sat Level 0.841 \n",
      "Overall acc 0.952 \n",
      "Overall sat 0.943\n",
      "Epoch 60: Train Sat Level 0.842 \n",
      "Overall acc 0.946 \n",
      "Overall sat 0.932\n",
      "Epoch 65: Train Sat Level 0.839 \n",
      "Overall acc 0.950 \n",
      "Overall sat 0.939\n",
      "Epoch 70: Train Sat Level 0.798 \n",
      "Overall acc 0.955 \n",
      "Overall sat 0.950\n",
      "Epoch 75: Train Sat Level 0.834 \n",
      "Overall acc 0.949 \n",
      "Overall sat 0.935\n",
      "Epoch 80: Train Sat Level 0.861 \n",
      "Overall acc 0.959 \n",
      "Overall sat 0.944\n",
      "Epoch 85: Train Sat Level 0.888 \n",
      "Overall acc 0.970 \n",
      "Overall sat 0.962\n",
      "Epoch 90: Train Sat Level 0.913 \n",
      "Overall acc 0.965 \n",
      "Overall sat 0.965\n",
      "Epoch 95: Train Sat Level 0.878 \n",
      "Overall acc 0.951 \n",
      "Overall sat 0.950\n",
      "Training finished at Epoch 99 with Sat Level 0.733\n"
     ]
    }
   ],
   "source": [
    "train_kwargs[\"Forall\"] = ltn.Quantifier(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=2, stable=True), quantifier='f')\n",
    "train_kwargs[\"Forall_custom\"]= ltn.Quantifier(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=10, stable=True), quantifier='f')\n",
    "train_kwargs[\"sat_agg\"] = ltn.fuzzy_ops.SatAgg(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=2, stable=True))\n",
    "train_kwargs[\"Implies\"] = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "\n",
    "\n",
    "first_run = True\n",
    "if first_run:\n",
    "    heatmap_data_abstr = []\n",
    "    AOM = ltn.Predicate(AbstractorOrderModel(object_dim, orderabstractor_kwargs))\n",
    "    # AOM = ltn.Predicate(BaselineRelationalModelConcat(object_dim, object_dim))\n",
    "\n",
    "heatmap_data_abstr += train(AOM, **train_kwargs, first_run=first_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4fcc54930cf49b4bd81964687f59d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Frame', max=20), Output()), _dom_classes=('widget-interaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# rules\n",
    "plot_mp(heatmap_data_abstr, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7182edeb834406fb2f7f75a28c63cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Frame', max=40), Output()), _dom_classes=('widget-interaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_mp(heatmap_data_abstr, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[146], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Godel = dict(\n",
    "    Not = ltn.Connective(ltn.fuzzy_ops.NotGodel()),\n",
    "    Not = ltn.Connective(ltn.fuzzy_ops.NotGodel()),\n",
    "    And = ltn.Connective(ltn.fuzzy_ops.AndMin()),\n",
    "    Or = ltn.Connective(ltn.fuzzy_ops.OrMax()),\n",
    "    Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesGodel()),\n",
    ")\n",
    "\n",
    "KleeneDienes = dict(\n",
    "    Not = ltn.Connective(ltn.fuzzy_ops.NotGodel()),\n",
    "    Not = ltn.Connective(ltn.fuzzy_ops.NotGodel()),\n",
    "    And = ltn.Connective(ltn.fuzzy_ops.AndMin()),\n",
    "    Or = ltn.Connective(ltn.fuzzy_ops.OrMax()),\n",
    "    Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesKleeneDienes()),\n",
    ")\n",
    "\n",
    "Goguen = dict(\n",
    "    Not = ltn.Connective(ltn.fuzzy_ops.NotStandard()),\n",
    "    And = ltn.Connective(ltn.fuzzy_ops.AndProd()),\n",
    "    Or = ltn.Connective(ltn.fuzzy_ops.OrProbSum()),\n",
    "    Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesGoguen()),\n",
    ")\n",
    "\n",
    "Reichenbach = dict(\n",
    "    Not = ltn.Connective(ltn.fuzzy_ops.NotStandard()),\n",
    "    And = ltn.Connective(ltn.fuzzy_ops.AndProd()),\n",
    "    Or = ltn.Connective(ltn.fuzzy_ops.OrProbSum()),\n",
    "    Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach()),\n",
    ")\n",
    "\n",
    "Luk = dict(\n",
    "    Not = ltn.Connective(ltn.fuzzy_ops.NotStandard()),\n",
    "    And = ltn.Connective(ltn.fuzzy_ops.AndLuk()),\n",
    "    Or = ltn.Connective(ltn.fuzzy_ops.OrLuk()),\n",
    "    Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesLuk()),\n",
    ")\n",
    "\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "Exists = ltn.Quantifier(ltn.fuzzy_ops.AggregPMean(p=6), quantifier=\"e\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Forall_pmean_error_p2 = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "Forall_pmean_error_p10 = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=10), quantifier=\"f\")\n",
    "Forall_min = ltn.Quantifier(ltn.fuzzy_ops.AggregMin(), quantifier=\"f\")\n",
    "Forall_mean = ltn.Quantifier(ltn.fuzzy_ops.AggregMean(), quantifier=\"f\")\n",
    "\n",
    "Forall_dict = dict(\n",
    "Forall_pmean_error_p2=Forall_pmean_error_p2,\n",
    "Forall_pmean_error_p10=Forall_pmean_error_p10,\n",
    "Forall_min=Forall_min,\n",
    "Forall_mean=Forall_mean,\n",
    ")\n",
    "\n",
    "Implies_reichenbach = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "Implies_kleene_diene = ltn.Connective(ltn.fuzzy_ops.ImpliesKleeneDienes())\n",
    "Implies_godel = ltn.Connective(ltn.fuzzy_ops.ImpliesGodel())\n",
    "Implies_Goguen = ltn.Connective(ltn.fuzzy_ops.ImpliesGoguen())\n",
    "Implies_Luk = ltn.Connective(ltn.fuzzy_ops.ImpliesLuk())\n",
    "\n",
    "Implies_Reichen_sigm_s3 = ltn.Connective(ImpliesReichenbachSigmoidal(s=3))\n",
    "Implies_Reichen_sigm_s9 = ltn.Connective(ImpliesReichenbachSigmoidal(s=9))\n",
    "Implies_Reichen_sigm_s18 = ltn.Connective(ImpliesReichenbachSigmoidal(s=18))\n",
    "\n",
    "\n",
    "\n",
    "Implies_dict = dict(\n",
    "    Implies_reichenbach=Implies_reichenbach,\n",
    "Implies_kleene_diene=Implies_kleene_diene,\n",
    "Implies_godel=Implies_godel,\n",
    "Implies_Luk=Implies_Luk,\n",
    "Implies_Goguen=Implies_Goguen,\n",
    "Implies_Reichen_sigm_s3=Implies_Reichen_sigm_s3,\n",
    "Implies_Reichen_sigm_s9=Implies_Reichen_sigm_s9,\n",
    "Implies_Reichen_sigm_s18=Implies_Reichen_sigm_s18,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'trans_abl_{object_dim}_independent.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "# object_dim = 32\n",
    "# with open(f'trans_abl_{object_dim}_independent.pkl', 'rb') as f:\n",
    "#     results[object_dim] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished at Epoch 1999 with Sat Level 0.997\n",
      "Training finished at Epoch 1999 with Sat Level 0.997\n",
      "Training finished at Epoch 1999 with Sat Level 0.974\n",
      "Training finished at Epoch 1999 with Sat Level 0.998\n"
     ]
    }
   ],
   "source": [
    "train_kwargs[\"sat_agg\"] = ltn.fuzzy_ops.SatAgg(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=2, stable=True))\n",
    "\n",
    "# results = {}\n",
    "\n",
    "for Forall in Forall_dict:\n",
    "    # results[Forall] = {}\n",
    "    # for Implies in Implies_dict:\n",
    "    for Implies in [\"Implies_Luk\"]:\n",
    "\n",
    "        train_kwargs[\"Forall\"] = Forall_dict[Forall]\n",
    "        train_kwargs[\"Forall_custom\"] = Forall_dict[Forall]\n",
    "        train_kwargs[\"Implies\"] = Implies_dict[Implies]\n",
    "\n",
    "        IOM = ltn.Predicate(BaselineRelationalIndependentModel(num_objects))\n",
    "        results[Forall][Implies] = train(IOM, **train_kwargs, first_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save to a pickle file\n",
    "with open(f'trans_abl_{object_dim}_independent.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92dc7294d00446abb67689af1216da0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Frame', max=27), Output()), _dom_classes=('widget-interaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trans_abl_last = [results[a][b][-1] for a in results for b in results[a]]\n",
    "plot_mp(trans_abl_last, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 40\n",
    "for Forall in Forall_dict:\n",
    "    for Implies in Implies_dict:\n",
    "        data = results[Forall][Implies]\n",
    "        file_name = f\"{Forall}_{Implies}_{50*i}_{object_dim}.png\"\n",
    "        save_plot_heatmap(data[i], pos_examples=pos_examples, file_name=file_name)\n",
    "        break\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot_heatmap(data, pos_examples, file_name, text=None):\n",
    "    plt.imshow(data, cmap=\"PuBu\", vmin=0, vmax=1)\n",
    "    # plt.colorbar()\n",
    "    if text:\n",
    "        plt.title(text)\n",
    "\n",
    "    # Mark specific grids (if provided)\n",
    "    for row, col in pos_examples:\n",
    "        plt.gca().add_patch(\n",
    "            plt.Rectangle(\n",
    "                (col - 0.475, row - 0.475),\n",
    "                0.95,\n",
    "                0.95,\n",
    "                edgecolor=\"yellow\",\n",
    "                fill=False,\n",
    "                lw=1,\n",
    "            )\n",
    "        )\n",
    "    data_dir = \"plots/trans_abl\"\n",
    "    file_path = os.path.join(\n",
    "                data_dir,\n",
    "                file_name\n",
    "            )\n",
    "    plt.savefig(\n",
    "        file_path,\n",
    "        # dpi=dpi,\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0.0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(data, text, pos_examples):\n",
    "    plt.imshow(data, cmap=\"PuBu\", vmin=0, vmax=1)\n",
    "    plt.colorbar()\n",
    "    plt.title(text)\n",
    "\n",
    "    # Mark specific grids (if provided)\n",
    "    for row, col in pos_examples:\n",
    "        plt.gca().add_patch(\n",
    "            plt.Rectangle(\n",
    "                (col - 0.475, row - 0.475),\n",
    "                0.95,\n",
    "                0.95,\n",
    "                edgecolor=\"yellow\",\n",
    "                fill=False,\n",
    "                lw=1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kwargs[\"sat_agg\"] = ltn.fuzzy_ops.SatAgg(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=2, stable=True))\n",
    "\n",
    "results = {}\n",
    "\n",
    "for Forall in Forall_dict:\n",
    "    results[Forall] = {}\n",
    "    for Implies in Implies_dict:\n",
    "        train_kwargs[\"Forall\"] = Forall_dict[Forall]\n",
    "        train_kwargs[\"Forall_custom\"] = Forall_dict[Forall]\n",
    "        train_kwargs[\"Implies\"] = Implies_dict[Implies]\n",
    "\n",
    "        IOM = ltn.Predicate(BaselineRelationalIndependentModel(num_objects))\n",
    "        results[Forall][Implies] = train(IOM, **train_kwargs, first_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kwargs[\"Forall\"] = ltn.Quantifier(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=2, stable=True), quantifier='f')\n",
    "train_kwargs[\"sat_agg\"] = ltn.fuzzy_ops.SatAgg(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=2, stable=True))\n",
    "\n",
    "first_run = True\n",
    "if first_run:\n",
    "    heatmap_data_abstr = []\n",
    "    AOM = ltn.Predicate(AbstractorOrderModel(object_dim, orderabstractor_kwargs))\n",
    "heatmap_data_abstr += train(AOM, **train_kwargs, first_run=first_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mp(heatmap_data_abstr, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_run = True\n",
    "if first_run:\n",
    "    heatmap_data_base_concat = []\n",
    "    AOM = ltn.Predicate(BaselineRelationalModelConcat(num_objects=num_objects, object_dim=object_dim))\n",
    "heatmap_data_base_concat += train(AOM, **train_kwargs, first_run=first_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mp(heatmap_data_base_concat, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # AOM = ltn.Predicate(AbstractorOrderModel(orderabstractor_kwargs))\n",
    "# train_kwargs[\"Forall\"] = ltn.Quantifier(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=20, stable=True), quantifier='f')\n",
    "\n",
    "# train_kwargs[\"Implies\"] = Implies_godel\n",
    "# train_kwargs[\"transitive\"]=True,\n",
    "# train_kwargs[\"switch\"]=False\n",
    "\n",
    "# AOM = torch.load(f\"checkpoints/chain_{object_dim}.PT\")\n",
    "# heatmap_data_abstr = train(AOM, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_mp(heatmap_data_abstr, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_abl08 = []\n",
    "\n",
    "train_kwargs[\"Forall\"] = ltn.Quantifier(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=4, stable=True), quantifier='f')\n",
    "\n",
    "train_kwargs[\"Implies\"] = Implies_godel\n",
    "train_kwargs[\"transitive\"]=True,\n",
    "train_kwargs[\"switch\"]=False\n",
    "\n",
    "# for Forall in Foralls_list:\n",
    "#     train_kwargs[\"Forall\"] = Forall\n",
    "\n",
    "for Implies in Implies_list:\n",
    "    train_kwargs[\"Implies\"] = Implies\n",
    "    AOM = torch.load(f\"checkpoints/chain_{object_dim}.PT\")\n",
    "    # AOM = ltn.Predicate(AbstractorOrderModel(orderabstractor_kwargs))\n",
    "    trans_abl08.append(train(AOM, **train_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save to a pickle file\n",
    "with open(f'trans_abl_{object_dim}_PMeanErrorp=4_w09.pkl', 'wb') as f:\n",
    "    pickle.dump(trans_abl08, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for Forall in Foralls_list:\n",
    "\n",
    "#     for Implies in Implies_list:\n",
    "#         print(i, Forall.agg_op, Implies.connective_op)\n",
    "#         i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_abl08_last = [a[-1] for a in trans_abl08]\n",
    "plot_mp(trans_abl08_last, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mp(trans_abl08[0], pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mp(trans_abl[-1], pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_abl_end = [a[-1] for a in trans_abl]\n",
    "plot_mp(trans_abl_end, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "Implies(And(AOM(c[i], c[i+1]), AOM(c[i+1], c[i+2])), AOM(c[i], c[i+2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3, 8, 10, 11\n",
    "i = 0\n",
    "for Forall in Foralls_list:\n",
    "    for Implies in Implies_list:\n",
    "        if i == 11:\n",
    "            print(Forall.agg_op, Implies.connective_op)\n",
    "            plot_mp(trans_abl[i], pos_examples=pos_examples, neg_examples=neg_examples)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = ltn.Predicate(BaselineRelationalModel(num_objects, object_dim, final_size=8))\n",
    "heatmap_data_R = train(R, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mp(heatmap_data_R, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rcat = ltn.Predicate(BaselineRelationalModelConcat(num_objects, object_dim))\n",
    "heatmap_data_Rcat = train(Rcat, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mp(heatmap_data_Rcat, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderabstractor_kwargs = {\n",
    "    \"num_layers\": 1,\n",
    "    \"norm\": None,  # Example normalization layer\n",
    "    \"use_pos_embedding\": False,\n",
    "    \"use_learned_symbols\": False,\n",
    "    \"learn_symbol_per_position\": False,\n",
    "    \"use_symbolic_attention\": True,\n",
    "    \"object_dim\": object_dim,\n",
    "    \"symbol_dim\": 64,  # Using a different symbol dimension\n",
    "    \"num_heads\": 1,\n",
    "    \"ff_dim\": 64,\n",
    "    \"dropout\": 0.1,\n",
    "    \"MHA_kwargs\": {\n",
    "        \"use_bias\": False,\n",
    "        \"activation\": torch.nn.Identity(),  # Different activation function\n",
    "        # \"activation\": nn.Softmax(-1),\n",
    "        # \"activation\": nn.Sigmoid(),\n",
    "        # \"activation\": sparsemax,\n",
    "        \"use_scaling\": True,\n",
    "        \"shared_kv_proj\": False,\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AOM = ltn.Predicate(AbstractorOrderModel(orderabstractor_kwargs))\n",
    "heatmap_data_abstr = train(AOM, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mp(heatmap_data_abstr, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderabstractor_kwargs = {\n",
    "    \"num_layers\": 1,\n",
    "    \"norm\": None,  # Example normalization layer\n",
    "    \"use_pos_embedding\": True,\n",
    "    \"use_learned_symbols\": False,\n",
    "    \"learn_symbol_per_position\": False,\n",
    "    \"use_symbolic_attention\": False,\n",
    "    \"object_dim\": object_dim,\n",
    "    \"symbol_dim\": 64,  # Using a different symbol dimension\n",
    "    \"num_heads\": 1,\n",
    "    \"ff_dim\": 64,\n",
    "    \"dropout\": 0.1,\n",
    "    \"MHA_kwargs\": {\n",
    "        \"use_bias\": False,\n",
    "        \"activation\": torch.nn.Identity(),  # Different activation function\n",
    "        # \"activation\": nn.Softmax(-1),\n",
    "        # \"activation\": nn.Sigmoid(),\n",
    "        # \"activation\": sparsemax,\n",
    "        \"use_scaling\": True,\n",
    "        \"shared_kv_proj\": False,\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AOM = ltn.Predicate(AbstractorOrderModel(orderabstractor_kwargs))\n",
    "heatmap_data_abstr = train(AOM, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mp(heatmap_data_abstr, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# data = heatmap_data_R[i]\n",
    "# plt.imshow(data, cmap=\"viridis\", vmin=0, vmax=1)\n",
    "# plt.colorbar()\n",
    "# plt.title(f\"Prediction after {20 * i} epoch\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LTN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "41e82446411d69384d72a304a49edf43449f9ad19ac7ac91cb04fd1f2b17f4cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
