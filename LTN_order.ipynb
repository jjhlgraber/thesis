{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import ltn\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n",
    "from utils_order import adjacency_anti_transitive, adjacency_triangular_lattice, adjacency_lattice, \\\n",
    "adjacency_total_order, adjacency_from_string, get_pairs_adjacency, get_samples_adjacency, \\\n",
    "get_constants, get_pairs_total_order, get_samples_total_order, get_eye_3D, get_sat, \\\n",
    "BaselineRelationalModel, BaselineRelationalModelConcat, AbstractorOrderModel, BaselineRelationalIndependentModel, plot_mp\n",
    "\n",
    "from custom_fuzzy_ops import ImpliesReichenbachSigmoidal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvModel(nn.Module):\n",
    "    def __init__(self, invariance=\"symmetric\", hidden_sizes=[16], Win=8, Wout=8):\n",
    "        super(InvModel, self).__init__()\n",
    "\n",
    "        self.invariance = invariance\n",
    "\n",
    "        # Determine input size based on invariance type\n",
    "        if self.invariance == \"none\":\n",
    "            input_size = Wout * 2  # No invariance, concatenate x and y\n",
    "        else:\n",
    "            Wout = Wout * 2  # Double Wout for invariance\n",
    "            input_size = Wout\n",
    "\n",
    "        self.W = nn.Linear(in_features=Win, out_features=Wout)\n",
    "\n",
    "        # Initialize hidden layers\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        layers = []\n",
    "        for hidden_size in self.hidden_sizes:\n",
    "            layers.append(nn.Linear(input_size, hidden_size, bias=False))\n",
    "            layers.append(nn.Tanh())\n",
    "            input_size = hidden_size\n",
    "        layers.append(nn.Linear(input_size, 1, bias=False))  # Output layer\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = self.W(x)\n",
    "        y = self.W(y)\n",
    "        if self.invariance == \"symmetric\":\n",
    "            xy = x + y\n",
    "        elif self.invariance == \"asymmetric\":\n",
    "            xy = x - y\n",
    "        elif self.invariance == \"none\":\n",
    "            xy = torch.cat([x, y], dim=-1)\n",
    "        xy = self.layers(xy)\n",
    "        truth = self.sigmoid(xy)\n",
    "        return truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Not = ltn.Connective(ltn.fuzzy_ops.NotStandard())\n",
    "And = ltn.Connective(ltn.fuzzy_ops.AndProd())\n",
    "Or = ltn.Connective(ltn.fuzzy_ops.OrProbSum())\n",
    "Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "Equiv = ltn.Connective(ltn.fuzzy_ops.Equiv(ltn.fuzzy_ops.AndProd(), ltn.fuzzy_ops.ImpliesReichenbach()))\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "Exists = ltn.Quantifier(ltn.fuzzy_ops.AggregPMean(p=6), quantifier=\"e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, constants_tensor, epoch_steps=50, epochs=1000, reflective=True, transitive=True, anti_transitive=False,\n",
    "          symmetric=False,\n",
    "          anti_symmetric=True, \n",
    "          connected=True,\n",
    "          LEM=True,\n",
    "          neg_examples=None, pos_examples=None, lr=0.001,\n",
    "          switch=False,\n",
    "          Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach()),\n",
    "          Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\"),\n",
    "          Forall_custom=ltn.Quantifier(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=10, stable=True), quantifier='f'),\n",
    "          first_run=True,\n",
    "          sat_agg=ltn.fuzzy_ops.SatAgg(),\n",
    "          ground_truth=None,\n",
    "          verbose=True):\n",
    "    \n",
    "    \n",
    "    heatmap_data = []\n",
    "    train_loss = []\n",
    "\n",
    "    if first_run:\n",
    "        x1 = ltn.Variable(\"x1\", constants_tensor)\n",
    "        x2 = ltn.Variable(\"x2\", constants_tensor)\n",
    "        query = model(x1,x2).value.detach().numpy()\n",
    "        heatmap_data.append(query)\n",
    "\n",
    "\n",
    "    # we need to learn the parameters of the predicate C\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    last_loss = np.inf\n",
    "    \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x1 = ltn.Variable(\"x1\", constants_tensor)\n",
    "        x2 = ltn.Variable(\"x2\", constants_tensor)\n",
    "        x3 = ltn.Variable(\"x3\", constants_tensor)\n",
    "\n",
    "        fuzzy_theory = []\n",
    "        fuzzy_weighted = []\n",
    "        if pos_examples is not None:\n",
    "            pos_x = ltn.Variable(\"pos_x\", constants_tensor[pos_examples[:,0]])\n",
    "            pos_y = ltn.Variable(\"pos_y\", constants_tensor[pos_examples[:,1]])\n",
    "            pos_x, pos_y = ltn.diag(pos_x, pos_y)\n",
    "            axiom_pos = Forall([pos_x, pos_y], model(pos_x, pos_y))\n",
    "            fuzzy_theory.append(axiom_pos)\n",
    "        if neg_examples is not None:\n",
    "            neg_x = ltn.Variable(\"neg_x\", constants_tensor[neg_examples[:,0]])\n",
    "            neg_y = ltn.Variable(\"neg_y\", constants_tensor[neg_examples[:,1]])\n",
    "            neg_x, neg_y = ltn.diag(neg_x, neg_y)\n",
    "            axiom_neg = Forall([neg_x, neg_y], Not(model(neg_x, neg_y)))\n",
    "            fuzzy_theory.append(axiom_neg)\n",
    "\n",
    "        if reflective:\n",
    "            fuzzy_theory.append(Forall(x1, model(x1, x1)))\n",
    "        if transitive:\n",
    "            eye_3D = torch.zeros(num_objects, num_objects, num_objects)\n",
    "            for i in range(num_objects):\n",
    "                eye_3D[i, i, i] = 1\n",
    "            eye_3D = eye_3D.bool()\n",
    "            fuzzy_weighted.append(\n",
    "                Forall_custom([x1, x2, x3], Implies(And(model(x1, x2), model(x2, x3)), model(x1, x3)),\n",
    "                                              cond_vars=[x1, x2, x3],\n",
    "                                              cond_fn=lambda x, y, z: eye_3D))\n",
    "\n",
    "                                            \n",
    "\n",
    "\n",
    "        if anti_transitive:\n",
    "            fuzzy_weighted.append(Forall_custom([x1, x2, x3], Implies(And(model(x1, x2), model(x2, x3)), Not(model(x1, x3))),) )\n",
    "\n",
    "        if symmetric:\n",
    "            fuzzy_theory.append(Forall_custom([x1, x2],\n",
    "                Implies(model(x1, x2), model(x2, x1)),\n",
    "                cond_vars=[x1, x2],\n",
    "                cond_fn=lambda x, y: ~torch.eye(num_objects, dtype=bool),\n",
    "                ))\n",
    "\n",
    "        if anti_symmetric:\n",
    "            fuzzy_theory.append(Forall([x1, x2],\n",
    "                Implies(model(x1, x2), Not(model(x2, x1))),\n",
    "                cond_vars=[x1, x2],\n",
    "                cond_fn=lambda x, y: ~torch.eye(num_objects, dtype=bool),\n",
    "                ))\n",
    "            \n",
    "        if connected:\n",
    "            axiom_connected = Forall_custom([x1, x2],\n",
    "                Or(model(x1, x2), model(x2, x1)),\n",
    "                )\n",
    "\n",
    "            fuzzy_theory.append(axiom_connected)\n",
    "        \n",
    "        if LEM:\n",
    "            axiom_lem = Forall_custom([x1, x2],\n",
    "                Or(model(x1, x2), Not(model(x1, x2))),\n",
    "                )\n",
    "            # axiom_lem = Forall_custom([x1, x2],\n",
    "            #     Implies(Not(model(x1, x2)), model(x1, x2)),\n",
    "            #     )\n",
    "\n",
    "            fuzzy_theory.append(axiom_lem)\n",
    "\n",
    "        weighted = False\n",
    "        if weighted:\n",
    "            sat_weight = 0.9\n",
    "            satisfiablity = sat_weight * sat_agg(*fuzzy_theory) + (1 - sat_weight) * sat_agg(*fuzzy_weighted)\n",
    "        else:\n",
    "            fuzzy_theory += fuzzy_weighted\n",
    "            satisfiablity = sat_agg(*fuzzy_theory)\n",
    "\n",
    "\n",
    "        loss = 1. - satisfiablity\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch%epoch_steps == 0:\n",
    "            with torch.no_grad():\n",
    "                train_loss.append(loss.item())\n",
    "                if verbose:\n",
    "                    print(\"Epoch %d: Train Sat Level %.3f \"%(epoch, satisfiablity))\n",
    "                query = model(x1,x2).value.detach().numpy()\n",
    "                heatmap_data.append(query)\n",
    "                if ground_truth is not None:\n",
    "                    pred = torch.tensor(query > 0.5)\n",
    "                    val_acc = (pred == ground_truth).sum() / (ground_truth.shape[0]**2)\n",
    "                    if verbose or True:\n",
    "                        print(\"Overall acc %.3f \"%(val_acc))\n",
    "\n",
    "                    mask = ~torch.eye(object_dim).bool()\n",
    "                    if verbose:\n",
    "                        print(\"Overall sat %.3f\"%(get_sat(query, ground_truth, mask=mask, p=1)))\n",
    "\n",
    "                # if np.allclose(loss.item(), last_loss, atol=1e-04, equal_nan=False) and epoch>25:\n",
    "                # # 1 - loss > 0.995 or \n",
    "                \n",
    "                #     if switch:\n",
    "                #         print()\n",
    "                #         print(epoch/epoch_steps)\n",
    "                #         torch.save(model, f\"checkpoints/chain_{object_dim}.PT\")\n",
    "                #         # break\n",
    "                    \n",
    "                #         switch = False\n",
    "                #         transitive = True\n",
    "                #         # Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=6), quantifier=\"f\")\n",
    "                #     else:\n",
    "                #         break\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            # last_loss = loss\n",
    "    if verbose:\n",
    "        print(\"Training finished at Epoch %d with Sat Level %.3f\" %(epoch, 1 - loss))\n",
    "    \n",
    "    return heatmap_data, train_loss, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_training(num_objects = 32, object_dim = None, feature_type = \"onehot\" ,pos_chain_depth = 1,\n",
    "    train_split_pos = 0.,\n",
    "    train_split_neg = 0.,):\n",
    "    if object_dim is None:\n",
    "        object_dim = num_objects\n",
    "\n",
    "    # adjacency = adjacency_anti_transitive(num_objects)\n",
    "    # adjacency = adjacency_triangular_lattice(num_objects)\n",
    "    # adjacency = adjacency_lattice(num_objects, \n",
    "    #                               dim=2,\n",
    "    #                             #   dim=int(np.log2(num_objects))\n",
    "    #                             distance=3,\n",
    "    #                             periodic=False\n",
    "    #                               )\n",
    "    # adjacency = adjacency_from_string(num_objects, \"O\")\n",
    "    adjacency = adjacency_total_order(num_objects)\n",
    "\n",
    "\n",
    "    # plt.imshow(adjacency, cmap='hot')\n",
    "    # plt.show()\n",
    "    # nx.draw(G, with_labels=True, arrows=True, pos=pos)\n",
    "\n",
    "\n",
    "    constants, constants_tensor = get_constants(num_objects, object_dim, feature_type)\n",
    "    # pos_pairs, neg_pairs = get_pairs_adjacency(adjacency=adjacency)\n",
    "    # pos_sample, neg_sample = get_samples_adjacency(pos_pairs, neg_pairs, train_split_pos, train_split_neg)\n",
    "\n",
    "    pos_pairs, neg_pairs = get_pairs_total_order(num_objects)\n",
    "    pos_sample, neg_sample = get_samples_total_order(num_objects, pos_pairs, neg_pairs, pos_chain_depth, train_split_pos, train_split_neg)\n",
    "    eye_3D = get_eye_3D(num_objects)\n",
    "    return num_objects, object_dim, adjacency, constants, constants_tensor, pos_pairs, neg_pairs, pos_sample, neg_sample, eye_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "(num_objects, object_dim, adjacency, \n",
    " constants, constants_tensor, pos_pairs, \n",
    " neg_pairs, pos_sample, neg_sample, \n",
    " eye_3D) = set_training(num_objects = 32, object_dim = None, \n",
    "                        # feature_type = \"index\" ,\n",
    "                        feature_type = \"onehot\" ,\n",
    "                        pos_chain_depth = False,\n",
    "                        train_split_pos = 0.05,\n",
    "                        train_split_neg = 0.05)\n",
    "\n",
    "pos_examples = pos_sample \n",
    "neg_examples = neg_sample\n",
    "\n",
    "# pos_examples = torch.Tensor([[i, i+1] for i in range(8-1)]).int()[[0,2,4,5,6]]\n",
    "# neg_examples = torch.Tensor([[i+2, i] for i in range(8-2)]).int()\n",
    "\n",
    "train_kwargs = dict(\n",
    "    epochs=100, epoch_steps=5,\n",
    "    reflective=False,\n",
    "    transitive=True,\n",
    "    anti_transitive=False,\n",
    "    symmetric=False,\n",
    "    anti_symmetric=False,\n",
    "    connected=False,\n",
    "    LEM=False,\n",
    "    pos_examples=pos_examples,\n",
    "    neg_examples=neg_examples,\n",
    "    # lr=0.01,\n",
    "    lr=0.01,\n",
    "    constants_tensor=constants_tensor,\n",
    "    switch=False,\n",
    "    ground_truth=adjacency\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall acc 0.547 \n",
      "Overall acc 0.680 \n",
      "Overall acc 0.744 \n",
      "Overall acc 0.772 \n",
      "Overall acc 0.792 \n",
      "Overall acc 0.792 \n",
      "Overall acc 0.779 \n",
      "Overall acc 0.776 \n",
      "Overall acc 0.769 \n",
      "Overall acc 0.771 \n",
      "Overall acc 0.771 \n",
      "Overall acc 0.771 \n",
      "Overall acc 0.771 \n",
      "Overall acc 0.771 \n",
      "Overall acc 0.771 \n",
      "Overall acc 0.771 \n",
      "Overall acc 0.770 \n",
      "Overall acc 0.771 \n",
      "Overall acc 0.771 \n",
      "Overall acc 0.771 \n"
     ]
    }
   ],
   "source": [
    "first_run = True\n",
    "if first_run:\n",
    "    heatmap_data_abstr = []\n",
    "    train_loss=[]\n",
    "    model = ltn.Predicate(InvModel(invariance=\"none\", hidden_sizes=[32,32], Win=object_dim, Wout=8))\n",
    "    # model = ltn.Predicate(InvModel(invariance=\"asymmetric\", hidden_sizes=[32,32], Win=object_dim, Wout=8))\n",
    "\n",
    "heatmap_data_abstr_last, train_loss_last = train(model, **train_kwargs, first_run=first_run, verbose=False)\n",
    "heatmap_data_abstr += heatmap_data_abstr_last\n",
    "train_loss += train_loss_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff38ae92205437fa402a68b78896f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Frame', max=20), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_mp(heatmap_data_abstr, pos_examples=pos_examples, neg_examples=neg_examples)\n",
    "plt.plot(train_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27cc8956739e4e85ba94678c467f6749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Frame', max=20), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x78430ad04160>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_mp(heatmap_data_abstr, pos_examples=pos_examples, neg_examples=neg_examples)\n",
    "plt.plot(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderabstractor_kwargs = {\n",
    "    \"num_layers\": 1,\n",
    "    \"norm\": None,  # Example normalization layer\n",
    "    \"use_pos_embedding\": False,\n",
    "    \"use_learned_symbols\": False,\n",
    "    \"learn_symbol_per_position\": False,\n",
    "    \"use_symbolic_attention\": True,\n",
    "    \"object_dim\": object_dim,\n",
    "    \"symbol_dim\": 64,  # Using a different symbol dimension\n",
    "    \"num_heads\": 1,\n",
    "    \"ff_dim\": 32,\n",
    "    \"dropout\": 0.1,\n",
    "    \"MHA_kwargs\": {\n",
    "        \"use_bias\": False,\n",
    "        \"activation\": torch.nn.Identity(),  # Different activation function\n",
    "        # \"activation\": nn.Softmax(-1),\n",
    "        # \"activation\": nn.Sigmoid(),\n",
    "        # \"activation\": sparsemax,\n",
    "        \"use_scaling\": True,\n",
    "        \"shared_kv_proj\": True,\n",
    "    },\n",
    "}\n",
    "\n",
    "first_run = True\n",
    "if first_run:\n",
    "    heatmap_data_abstr = []\n",
    "    train_loss=[]\n",
    "    AOM = ltn.Predicate(AbstractorOrderModel(object_dim, orderabstractor_kwargs))\n",
    "heatmap_data_abstr_last, train_loss_last = train(AOM, **train_kwargs, first_run=first_run)\n",
    "heatmap_data_abstr += heatmap_data_abstr_last\n",
    "train_loss += train_loss_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kwargs[\"Forall\"] = ltn.Quantifier(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=10, stable=True), quantifier='f')\n",
    "train_kwargs[\"Forall_custom\"]= ltn.Quantifier(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=10, stable=True), quantifier='f')\n",
    "train_kwargs[\"sat_agg\"] = ltn.fuzzy_ops.SatAgg(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=2, stable=True))\n",
    "train_kwargs[\"Implies\"] = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "# train_kwargs[\"Implies\"] = ltn.Connective(ltn.fuzzy_ops.ImpliesGodel())\n",
    "\n",
    "# train_kwargs[\"Implies\"] = list(Implies_dict.values())[1]\n",
    "print(train_kwargs[\"Implies\"])\n",
    "\n",
    "\n",
    "first_run = True\n",
    "if first_run:\n",
    "    heatmap_data_ind = []\n",
    "    train_loss=[]\n",
    "    model = BaselineRelationalIndependentModel(object_dim)\n",
    "    shape = model.lin.weight.shape\n",
    "    model.lin.weight = torch.nn.Parameter(torch.ones(shape)-0.+torch.rand(shape), requires_grad=True)\n",
    "    AOM = ltn.Predicate(model)\n",
    "heatmap_data_ind_last, train_loss_last = train(AOM, **train_kwargs, first_run=first_run)\n",
    "heatmap_data_ind += heatmap_data_ind_last\n",
    "train_loss += train_loss_last\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mp(heatmap_data_ind, pos_examples=pos_examples, neg_examples=neg_examples)\n",
    "plt.plot(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(num_objects, object_dim, adjacency, \n",
    " constants, constants_tensor, pos_pairs, \n",
    " neg_pairs, pos_sample, neg_sample, \n",
    " eye_3D) = set_training(num_objects = 32, object_dim = None, \n",
    "                        # feature_type = \"index\" ,\n",
    "                        feature_type = \"onehot\" ,\n",
    "                        pos_chain_depth = 1,\n",
    "                        train_split_pos = 0,\n",
    "                        train_split_neg = 0.1)\n",
    "\n",
    "pos_examples = pos_sample \n",
    "neg_examples = neg_sample\n",
    "\n",
    "# pos_examples = torch.Tensor([[i, i+1] for i in range(8-1)]).int()[[0,2,4,5,6]]\n",
    "# neg_examples = torch.Tensor([[i+2, i] for i in range(8-2)]).int()\n",
    "\n",
    "train_kwargs = dict(\n",
    "    epochs=100, epoch_steps=5,\n",
    "    reflective=False,\n",
    "    transitive=True,\n",
    "    anti_transitive=False,\n",
    "    symmetric=False,\n",
    "    anti_symmetric=True,\n",
    "    connected=True,\n",
    "    LEM=False,\n",
    "    pos_examples=pos_examples,\n",
    "    neg_examples=neg_examples,\n",
    "    # lr=0.01,\n",
    "    lr=0.01,\n",
    "    constants_tensor=constants_tensor,\n",
    "    switch=False,\n",
    "    ground_truth=adjacency\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kwargs[\"Forall\"] = ltn.Quantifier(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=2, stable=True), quantifier='f')\n",
    "train_kwargs[\"Forall_custom\"]= ltn.Quantifier(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=10, stable=True), quantifier='f')\n",
    "train_kwargs[\"sat_agg\"] = ltn.fuzzy_ops.SatAgg(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=2, stable=True))\n",
    "train_kwargs[\"Implies\"] = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "\n",
    "\n",
    "first_run = True\n",
    "if first_run:\n",
    "    heatmap_data_abstr = []\n",
    "    AOM = ltn.Predicate(AbstractorOrderModel(object_dim, orderabstractor_kwargs))\n",
    "    # AOM = ltn.Predicate(BaselineRelationalModelConcat(object_dim, object_dim))\n",
    "\n",
    "heatmap_data_abstr += train(AOM, **train_kwargs, first_run=first_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rules\n",
    "plot_mp(heatmap_data_abstr, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mp(heatmap_data_abstr, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Godel = dict(\n",
    "    Not = ltn.Connective(ltn.fuzzy_ops.NotGodel()),\n",
    "    And = ltn.Connective(ltn.fuzzy_ops.AndMin()),\n",
    "    Or = ltn.Connective(ltn.fuzzy_ops.OrMax()),\n",
    "    Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesGodel()),\n",
    ")\n",
    "\n",
    "KleeneDienes = dict(\n",
    "    Not = ltn.Connective(ltn.fuzzy_ops.NotGodel()),\n",
    "    And = ltn.Connective(ltn.fuzzy_ops.AndMin()),\n",
    "    Or = ltn.Connective(ltn.fuzzy_ops.OrMax()),\n",
    "    Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesKleeneDienes()),\n",
    ")\n",
    "\n",
    "Goguen = dict(\n",
    "    Not = ltn.Connective(ltn.fuzzy_ops.NotStandard()),\n",
    "    And = ltn.Connective(ltn.fuzzy_ops.AndProd()),\n",
    "    Or = ltn.Connective(ltn.fuzzy_ops.OrProbSum()),\n",
    "    Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesGoguen()),\n",
    ")\n",
    "\n",
    "Reichenbach = dict(\n",
    "    Not = ltn.Connective(ltn.fuzzy_ops.NotStandard()),\n",
    "    And = ltn.Connective(ltn.fuzzy_ops.AndProd()),\n",
    "    Or = ltn.Connective(ltn.fuzzy_ops.OrProbSum()),\n",
    "    Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach()),\n",
    ")\n",
    "\n",
    "Luk = dict(\n",
    "    Not = ltn.Connective(ltn.fuzzy_ops.NotStandard()),\n",
    "    And = ltn.Connective(ltn.fuzzy_ops.AndLuk()),\n",
    "    Or = ltn.Connective(ltn.fuzzy_ops.OrLuk()),\n",
    "    Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesLuk()),\n",
    ")\n",
    "\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "Exists = ltn.Quantifier(ltn.fuzzy_ops.AggregPMean(p=6), quantifier=\"e\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Forall_pmean_error_p2 = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "Forall_pmean_error_p10 = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=10), quantifier=\"f\")\n",
    "Forall_min = ltn.Quantifier(ltn.fuzzy_ops.AggregMin(), quantifier=\"f\")\n",
    "Forall_mean = ltn.Quantifier(ltn.fuzzy_ops.AggregMean(), quantifier=\"f\")\n",
    "\n",
    "Forall_dict = dict(\n",
    "Forall_pmean_error_p2=Forall_pmean_error_p2,\n",
    "Forall_pmean_error_p10=Forall_pmean_error_p10,\n",
    "Forall_min=Forall_min,\n",
    "Forall_mean=Forall_mean,\n",
    ")\n",
    "\n",
    "Implies_reichenbach = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "Implies_kleene_diene = ltn.Connective(ltn.fuzzy_ops.ImpliesKleeneDienes())\n",
    "Implies_godel = ltn.Connective(ltn.fuzzy_ops.ImpliesGodel())\n",
    "Implies_Goguen = ltn.Connective(ltn.fuzzy_ops.ImpliesGoguen())\n",
    "Implies_Luk = ltn.Connective(ltn.fuzzy_ops.ImpliesLuk())\n",
    "\n",
    "Implies_Reichen_sigm_s3 = ltn.Connective(ImpliesReichenbachSigmoidal(s=3))\n",
    "Implies_Reichen_sigm_s9 = ltn.Connective(ImpliesReichenbachSigmoidal(s=9))\n",
    "Implies_Reichen_sigm_s18 = ltn.Connective(ImpliesReichenbachSigmoidal(s=18))\n",
    "\n",
    "\n",
    "\n",
    "Implies_dict = dict(\n",
    "    Implies_reichenbach=Implies_reichenbach,\n",
    "Implies_kleene_diene=Implies_kleene_diene,\n",
    "Implies_godel=Implies_godel,\n",
    "Implies_Luk=Implies_Luk,\n",
    "Implies_Goguen=Implies_Goguen,\n",
    "Implies_Reichen_sigm_s3=Implies_Reichen_sigm_s3,\n",
    "Implies_Reichen_sigm_s9=Implies_Reichen_sigm_s9,\n",
    "Implies_Reichen_sigm_s18=Implies_Reichen_sigm_s18,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'trans_abl_{object_dim}_independent.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "# object_dim = 32\n",
    "# with open(f'trans_abl_{object_dim}_independent.pkl', 'rb') as f:\n",
    "#     results[object_dim] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kwargs[\"sat_agg\"] = ltn.fuzzy_ops.SatAgg(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=2, stable=True))\n",
    "\n",
    "# results = {}\n",
    "\n",
    "for Forall in Forall_dict:\n",
    "    # results[Forall] = {}\n",
    "    # for Implies in Implies_dict:\n",
    "    for Implies in [\"Implies_Luk\"]:\n",
    "\n",
    "        train_kwargs[\"Forall\"] = Forall_dict[Forall]\n",
    "        train_kwargs[\"Forall_custom\"] = Forall_dict[Forall]\n",
    "        train_kwargs[\"Implies\"] = Implies_dict[Implies]\n",
    "\n",
    "        IOM = ltn.Predicate(BaselineRelationalIndependentModel(num_objects))\n",
    "        results[Forall][Implies] = train(IOM, **train_kwargs, first_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save to a pickle file\n",
    "with open(f'trans_abl_{object_dim}_independent.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_abl_last = [results[a][b][-1] for a in results for b in results[a]]\n",
    "plot_mp(trans_abl_last, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 40\n",
    "for Forall in Forall_dict:\n",
    "    for Implies in Implies_dict:\n",
    "        data = results[Forall][Implies]\n",
    "        file_name = f\"{Forall}_{Implies}_{50*i}_{object_dim}.png\"\n",
    "        save_plot_heatmap(data[i], pos_examples=pos_examples, file_name=file_name)\n",
    "        break\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot_heatmap(data, pos_examples, file_name, text=None):\n",
    "    plt.imshow(data, cmap=\"PuBu\", vmin=0, vmax=1)\n",
    "    # plt.colorbar()\n",
    "    if text:\n",
    "        plt.title(text)\n",
    "\n",
    "    # Mark specific grids (if provided)\n",
    "    for row, col in pos_examples:\n",
    "        plt.gca().add_patch(\n",
    "            plt.Rectangle(\n",
    "                (col - 0.475, row - 0.475),\n",
    "                0.95,\n",
    "                0.95,\n",
    "                edgecolor=\"yellow\",\n",
    "                fill=False,\n",
    "                lw=1,\n",
    "            )\n",
    "        )\n",
    "    data_dir = \"plots/trans_abl\"\n",
    "    file_path = os.path.join(\n",
    "                data_dir,\n",
    "                file_name\n",
    "            )\n",
    "    plt.savefig(\n",
    "        file_path,\n",
    "        # dpi=dpi,\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0.0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(data, text, pos_examples):\n",
    "    plt.imshow(data, cmap=\"PuBu\", vmin=0, vmax=1)\n",
    "    plt.colorbar()\n",
    "    plt.title(text)\n",
    "\n",
    "    # Mark specific grids (if provided)\n",
    "    for row, col in pos_examples:\n",
    "        plt.gca().add_patch(\n",
    "            plt.Rectangle(\n",
    "                (col - 0.475, row - 0.475),\n",
    "                0.95,\n",
    "                0.95,\n",
    "                edgecolor=\"yellow\",\n",
    "                fill=False,\n",
    "                lw=1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kwargs[\"sat_agg\"] = ltn.fuzzy_ops.SatAgg(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=2, stable=True))\n",
    "\n",
    "results = {}\n",
    "\n",
    "for Forall in Forall_dict:\n",
    "    results[Forall] = {}\n",
    "    for Implies in Implies_dict:\n",
    "        train_kwargs[\"Forall\"] = Forall_dict[Forall]\n",
    "        train_kwargs[\"Forall_custom\"] = Forall_dict[Forall]\n",
    "        train_kwargs[\"Implies\"] = Implies_dict[Implies]\n",
    "\n",
    "        IOM = ltn.Predicate(BaselineRelationalIndependentModel(num_objects))\n",
    "        results[Forall][Implies] = train(IOM, **train_kwargs, first_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kwargs[\"Forall\"] = ltn.Quantifier(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=2, stable=True), quantifier='f')\n",
    "train_kwargs[\"sat_agg\"] = ltn.fuzzy_ops.SatAgg(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=2, stable=True))\n",
    "\n",
    "first_run = True\n",
    "if first_run:\n",
    "    heatmap_data_abstr = []\n",
    "    AOM = ltn.Predicate(AbstractorOrderModel(object_dim, orderabstractor_kwargs))\n",
    "heatmap_data_abstr += train(AOM, **train_kwargs, first_run=first_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mp(heatmap_data_abstr, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_run = True\n",
    "if first_run:\n",
    "    heatmap_data_base_concat = []\n",
    "    AOM = ltn.Predicate(BaselineRelationalModelConcat(num_objects=num_objects, object_dim=object_dim))\n",
    "heatmap_data_base_concat += train(AOM, **train_kwargs, first_run=first_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mp(heatmap_data_base_concat, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # AOM = ltn.Predicate(AbstractorOrderModel(orderabstractor_kwargs))\n",
    "# train_kwargs[\"Forall\"] = ltn.Quantifier(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=20, stable=True), quantifier='f')\n",
    "\n",
    "# train_kwargs[\"Implies\"] = Implies_godel\n",
    "# train_kwargs[\"transitive\"]=True,\n",
    "# train_kwargs[\"switch\"]=False\n",
    "\n",
    "# AOM = torch.load(f\"checkpoints/chain_{object_dim}.PT\")\n",
    "# heatmap_data_abstr = train(AOM, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_mp(heatmap_data_abstr, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_abl08 = []\n",
    "\n",
    "train_kwargs[\"Forall\"] = ltn.Quantifier(agg_op=ltn.fuzzy_ops.AggregPMeanError(p=4, stable=True), quantifier='f')\n",
    "\n",
    "train_kwargs[\"Implies\"] = Implies_godel\n",
    "train_kwargs[\"transitive\"]=True,\n",
    "train_kwargs[\"switch\"]=False\n",
    "\n",
    "# for Forall in Foralls_list:\n",
    "#     train_kwargs[\"Forall\"] = Forall\n",
    "\n",
    "for Implies in Implies_list:\n",
    "    train_kwargs[\"Implies\"] = Implies\n",
    "    AOM = torch.load(f\"checkpoints/chain_{object_dim}.PT\")\n",
    "    # AOM = ltn.Predicate(AbstractorOrderModel(orderabstractor_kwargs))\n",
    "    trans_abl08.append(train(AOM, **train_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save to a pickle file\n",
    "with open(f'trans_abl_{object_dim}_PMeanErrorp=4_w09.pkl', 'wb') as f:\n",
    "    pickle.dump(trans_abl08, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for Forall in Foralls_list:\n",
    "\n",
    "#     for Implies in Implies_list:\n",
    "#         print(i, Forall.agg_op, Implies.connective_op)\n",
    "#         i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_abl08_last = [a[-1] for a in trans_abl08]\n",
    "plot_mp(trans_abl08_last, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mp(trans_abl08[0], pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mp(trans_abl[-1], pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_abl_end = [a[-1] for a in trans_abl]\n",
    "plot_mp(trans_abl_end, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "Implies(And(AOM(c[i], c[i+1]), AOM(c[i+1], c[i+2])), AOM(c[i], c[i+2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3, 8, 10, 11\n",
    "i = 0\n",
    "for Forall in Foralls_list:\n",
    "    for Implies in Implies_list:\n",
    "        if i == 11:\n",
    "            print(Forall.agg_op, Implies.connective_op)\n",
    "            plot_mp(trans_abl[i], pos_examples=pos_examples, neg_examples=neg_examples)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = ltn.Predicate(BaselineRelationalModel(num_objects, object_dim, final_size=8))\n",
    "heatmap_data_R = train(R, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mp(heatmap_data_R, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rcat = ltn.Predicate(BaselineRelationalModelConcat(num_objects, object_dim))\n",
    "heatmap_data_Rcat = train(Rcat, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mp(heatmap_data_Rcat, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AOM = ltn.Predicate(AbstractorOrderModel(orderabstractor_kwargs))\n",
    "heatmap_data_abstr = train(AOM, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mp(heatmap_data_abstr, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderabstractor_kwargs = {\n",
    "    \"num_layers\": 1,\n",
    "    \"norm\": None,  # Example normalization layer\n",
    "    \"use_pos_embedding\": True,\n",
    "    \"use_learned_symbols\": False,\n",
    "    \"learn_symbol_per_position\": False,\n",
    "    \"use_symbolic_attention\": False,\n",
    "    \"object_dim\": object_dim,\n",
    "    \"symbol_dim\": 64,  # Using a different symbol dimension\n",
    "    \"num_heads\": 1,\n",
    "    \"ff_dim\": 64,\n",
    "    \"dropout\": 0.1,\n",
    "    \"MHA_kwargs\": {\n",
    "        \"use_bias\": False,\n",
    "        \"activation\": nn.Identity(),  # Different activation function\n",
    "        # \"activation\": nn.Softmax(-1),\n",
    "        # \"activation\": nn.Sigmoid(),\n",
    "        # \"activation\": sparsemax,\n",
    "        \"use_scaling\": True,\n",
    "        \"shared_kv_proj\": False,\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AOM = ltn.Predicate(AbstractorOrderModel(orderabstractor_kwargs))\n",
    "heatmap_data_abstr = train(AOM, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mp(heatmap_data_abstr, pos_examples=pos_examples, neg_examples=neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# data = heatmap_data_R[i]\n",
    "# plt.imshow(data, cmap=\"viridis\", vmin=0, vmax=1)\n",
    "# plt.colorbar()\n",
    "# plt.title(f\"Prediction after {20 * i} epoch\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LTN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "41e82446411d69384d72a304a49edf43449f9ad19ac7ac91cb04fd1f2b17f4cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
