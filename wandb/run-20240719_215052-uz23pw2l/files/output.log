  | Name          | Type               | Params | Mode
-------------------------------------------------------------
0 | embedder      | Sequential         | 0      | train
1 | aggregate_seq | Flatten            | 0      | train
2 | final_layer   | SetClassifierLayer | 148    | train
-------------------------------------------------------------
148       Trainable params
0         Non-trainable params
148       Total params
0.001     Total estimated model params size (MB)
/home/job/miniconda3/envs/LTN/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:105: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.
/home/job/miniconda3/envs/LTN/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=50` reached.